{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adce6103-99ea-44ee-ae2c-b35e081ec5a2",
   "metadata": {},
   "source": [
    "# FashionMNIST Image Classification with ResNet18 fine-tuning\n",
    "\n",
    "## Overview\n",
    "This notebook implements a Transfer Learning approach to classify images from the **FashionMNIST** dataset. We adapt a pre-trained **ResNet18** architecture (originally designed for ImageNet) to handle 28x28 grayscale fashion items.\n",
    "\n",
    "## Technical Approach\n",
    "* **Model:** ResNet18 (Residual Neural Network) with modified input/output layers.\n",
    "* **Regularization:** Data Augmentation (Rotation, Flipping) and Dropout.\n",
    "* **Optimization:** Adam Optimizer with CrossEntropyLoss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01d1ab5-6c5b-4509-9d88-05ccd77b9614",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install datasets\n",
    "#!pip install torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader , random_split\n",
    "from torchvision import datasets , models , transforms \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dd6494-a92c-432a-972e-54c4874ef4e9",
   "metadata": {},
   "source": [
    "## Data Augmentation & Loading\n",
    "Utilizing `torchvision.transforms` to \"expand\" the training dataset and prevent overfitting.\n",
    "* **Resize:** Upscaling images to 224x224 (standard input for ResNet).\n",
    "* **Random Rotation (15°):** Makes the model robust to orientation changes.\n",
    "* **Random Horizontal Flip:** Simulates different viewing angles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac24435-c0b7-476e-ae72-7363a5b9d424",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "learning_rate = 1e-4\n",
    "epochs = 10\n",
    "hidden_units = 256\n",
    "resize_dim = 224\n",
    "\n",
    "train_transform = transforms.Compose( [ transforms.Resize((resize_dim , resize_dim)) , transforms.RandomHorizontalFlip(p=0.5) ,\n",
    "                                       transforms.RandomRotation(degrees=15) , transforms.ToTensor() , transforms.Normalize(mean=[0.5] , std = [0.5])\n",
    "                                      ])\n",
    "val_test_transform = transforms.Compose( [ transforms.Resize((resize_dim , resize_dim)) , transforms.ToTensor() , transforms.Normalize(mean = [0.5] , std = [0.5]) ])\n",
    "\n",
    "full_train_ds = datasets.FashionMNIST(root='./data', train=True, download=True, transform=train_transform)\n",
    "test_ds = datasets.FashionMNIST(root='./data', train=False, download=True, transform=val_test_transform)\n",
    "\n",
    "train_size = int(0.8*len(full_train_ds))\n",
    "dev_size = len(full_train_ds) - train_size\n",
    "train_ds , dev_ds = random_split(full_train_ds , [train_size , dev_size])\n",
    "\n",
    "train_loader = DataLoader(train_ds , batch_size = batch_size , shuffle = True , num_workers = 2)\n",
    "dev_loader = DataLoader(dev_ds , batch_size = batch_size , shuffle = False , num_workers = 2)\n",
    "test_loader = DataLoader(test_ds , batch_size = batch_size , shuffle = False , num_workers = 2)\n",
    "final_train_loader = DataLoader(full_train_ds , batch_size = batch_size , shuffle = True , num_workers = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478b658a-7fb5-46ad-a3cf-0c2e94c4e644",
   "metadata": {},
   "source": [
    "## Model Architecture: Adapted ResNet18\n",
    "The standard ResNet18 expects 3-channel RGB images (ImageNet). We modify it to work with FashionMNIST (1-channel):\n",
    "\n",
    "1.  **Input Layer:** Changed the first Convolutional layer (`conv1`) to accept **1 channel** (grayscale) instead of 3.\n",
    "2.  **Backbone:** Using the pre-trained weights (`ResNet18_Weights.DEFAULT`) to leverage learned feature extractors.\n",
    "3.  **Classifier Head:** Replacing the final Fully Connected layer with a custom MLP:\n",
    "    * Linear Layer -> ReLU -> Dropout (0.5) -> Output Layer (10 classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdab770-6091-41aa-a3cf-bf98b6cc9535",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTmodel(nn.Module):\n",
    "    def __init__(self , hidden_units , num_classes=10):\n",
    "        super(FashionMNISTmodel , self).__init__()\n",
    "        self.resnet = models.resnet18( weights = models.ResNet18_Weights.DEFAULT)\n",
    "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        in_features = self.resnet.fc.in_features\n",
    "\n",
    "        self.resnet.fc = nn.Sequential( nn.Linear(in_features , hidden_units) , nn.ReLU() , nn.Dropout(0.5) , nn.Linear(hidden_units , num_classes))\n",
    "\n",
    "    def forward(self , x):\n",
    "            return self.resnet(x)\n",
    "\n",
    "model = FashionMNISTmodel(hidden_units = hidden_units).to(device)\n",
    "optimizer = optim.Adam(model.parameters() , lr = learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d081a3-9ddb-449c-b656-2da4bd184bd6",
   "metadata": {},
   "source": [
    "## Training & Validation\n",
    "Training the model for 10 epochs using the **Adam** optimizer . The loss is tracked on both Training and Development sets to identify the optimal stopping point (best epoch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc5ba94-fee1-49a3-b44f-3ba916c07a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "dev_losses = []\n",
    "#εύρεση καλύτερου αριθμού εποχών\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for images , labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs , labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    average_train_loss = train_loss / len(train_loader)\n",
    "    train_losses.append(average_train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    dev_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images , labels in dev_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs , labels)\n",
    "            dev_loss += loss.item()\n",
    "\n",
    "    average_dev_loss = dev_loss / len(dev_loader)\n",
    "    dev_losses.append(average_dev_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21d53c8-f7fe-4717-bf27-1112084b73f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = np.argmin(dev_losses) + 1\n",
    "\n",
    "epochs_range = range(1, len(train_losses) + 1)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs_range ,train_losses, label='Train Data Loss ')\n",
    "plt.plot(epochs_range , dev_losses, label='Dev Data Loss ')\n",
    "plt.title('Loss Per Epoch')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xticks(epochs_range)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de695737-c128-49a8-bdcd-ccc30d4f6608",
   "metadata": {},
   "source": [
    "## Final Evaluation\n",
    "Identifying the best epoch, retraining the model on the **Full Training Set** and evaluating it on the **Test Set**.\n",
    "\n",
    "The table below details the Precision, Recall, and F1-Score for each of the 10 fashion categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff6c162-35c9-4476-8a4b-8b5af4069bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = FashionMNISTmodel(hidden_units = hidden_units).to(device)\n",
    "final_optimizer = optim.Adam(final_model.parameters() , lr = learning_rate)\n",
    "\n",
    "final_model.train()\n",
    "for epoch in range(best_epoch):\n",
    "    final_train_loss = 0.0\n",
    "    for images , labels in final_train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        final_optimizer.zero_grad()\n",
    "        outputs = final_model(images)\n",
    "        loss = criterion(outputs , labels)\n",
    "        loss.backward()\n",
    "        final_optimizer.step()\n",
    "        final_train_loss += loss.item()\n",
    "\n",
    "    average_loss = final_train_loss / len(final_train_loader)\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "final_model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = final_model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "report_dict = classification_report(all_labels, all_preds, target_names=class_names, output_dict=True)\n",
    "df_report = pd.DataFrame(report_dict).transpose()\n",
    "\n",
    "print(\"Test Data Stats\")\n",
    "print(df_report[['precision', 'recall', 'f1-score']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
